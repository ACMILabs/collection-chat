<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ACMI anecdote machine</title>
    <link href="static/styles.css" rel="stylesheet">
    <link rel="icon" type="image/x-icon" href="static/favicon.ico">
    <meta id="results" data-name="results" data-results="{{results}}">
    <meta id="query" data-name="query" data-query="{{query}}">
</head>

<body>
    <header>
        <h1><a href="/?json=false" title="Take me home">The anecdote machine</a></h1>
        {% if voice == 'Seb Chan' %}
            <h2>The ghost in the machine is AI <a href="https://www.acmi.net.au/about/who-we-are/seb-chan/" target="_blank">{{ voice }}</a>, ACMI's CEO and Director</h2>
        {% else %}
            <h2>The ghost in the machine is AI {{ voice }}</h2>
        {% endif %}
        <h3 class="disclaimer">All answers are generated by passing <a href="https://api.acmi.net.au" target="_blank">ACMI collection data</a> similar to your request (using <a href="https://labs.acmi.net.au/embeddings-and-our-collection-afa815b8406e" target="_blank">embeddings algorithms</a>), to a large language model ({{ model }}). So please use them with caution.</h3>
    </header>

    <form>
        <input id="randomBtn" type="submit" value="I'm feeling lucky">
        <input type="hidden" name="json" id="json" value="false">
        <input type="hidden" name="random" id="random" value="true">
    </form>

    <ol id="chats"></ol>

    <audio controls id="audioPlayer">
        <source src="static/audio/seb-hmmm.mp3" type="audio/mp3">
    </audio>

    <ul id="resultsList">
        {% for result in results %}
        <li>
            <a href="https://url.acmi.net.au/w/{{ result.id }}" target="_blank"><div class="circle"><div class="image"></div></div></a>
            <h3><a href="https://url.acmi.net.au/w/{{ result.id }}" target="_blank">{{ result.title }}</a></h3>
            <p>{{ result.headline_credit }}</p>
            <p><a href="https://url.acmi.net.au/w/{{ result.id }}" target="_blank">Read more...</a></p>
        </li>
        {% endfor %}
    </ul>

    <form id="searchForm">
        <input type="text" name="query" id="queryInput"
            placeholder="{% if query %}{% else %}I'm looking for...{% endif %}"
            value="{% if query %}{{ query }}{% endif %}">
        <input type="hidden" name="json" id="json" value="false">
    </form>

    <p><a href="https://www.acmi.net.au"><img class="logo" src="static/images/acmi-logo-white.svg" alt="An ACMI labs experiment" title="An ACMI labs experiment" /></a></p>

    <script>
        var hasPlayed = false;
        const searchForm = document.getElementById('searchForm');
        const queryInput = document.getElementById('queryInput');
        const randomButton = document.getElementById('randomBtn');
        const resultsList = document.getElementById('resultsList');
        const chatsElement = document.getElementById('chats');
        const audioPlayer = document.getElementById('audioPlayer');

        if (isSafari()) {
            audioPlayer.style.width = '2rem';
        }

        /* Plays Seb's voice when visitors tap in the query field. */
        document.onclick = function (event) {
            var audio = document.getElementsByTagName('audio')[0];
            if (!hasPlayed && queryInput.value === "" && event.target.type === 'text') {
                // Set the audio source to the new URL and play it
                const sourceElement = audio.querySelector('source');
                sourceElement.src = 'static/audio/seb-are-you-looking-for-something.mp3';
                audio.load();
                audio.play();
                hasPlayed = true;
            }
        }

        /* Play the chat when tapped. */
        var chats = document.getElementById('chats');
        chats.onclick = function (event) {
            var audio = document.getElementsByTagName('audio')[0];
            audio.play();
        }

        /**
         * On page load, or when user presses back/forward, we parse the URL
         * and fetch data if needed. This gives us a single-page-app feel.
         */
        window.addEventListener('popstate', handlePopState);

        // Call handlePopState() once at initial load
        document.addEventListener('DOMContentLoaded', () => {
            handlePopState();
        });

        /**
         * For the query form: when user clicks "Search",
         * we do a GET /?json=true&query=... (without reloading),
         * update the address bar, then summarise+stream TTS.
         */
        searchForm.addEventListener('submit', async (event) => {
            event.preventDefault();
            chatsElement.innerHTML = '';
            resultsList.innerHTML = '';
            const query = queryInput.value.trim();
            if (!query) return;

            // Update the URL for shareability
            const newUrl = new URL(window.location);
            newUrl.searchParams.set('query', query);
            newUrl.searchParams.delete('random'); // Remove random if present
            newUrl.searchParams.set('json', 'false'); // or remove it entirely if you prefer
            window.history.pushState({}, '', newUrl);

            // Now fetch data from the server
            await fetchCollectionData(query, false);
        });

        /**
         * For the "Suggest Something Random" button:
         */
        randomButton.addEventListener('click', async () => {
            event.preventDefault();
            chatsElement.innerHTML = '';
            resultsList.innerHTML = '';
            queryInput.value = '';
            if (!hasPlayed) {
                const audio = document.getElementsByTagName('audio')[0];
                audio.play();
                hasPlayed = true;
            }
            const newUrl = new URL(window.location);
            newUrl.searchParams.delete('query');
            newUrl.searchParams.set('random', 'true');
            newUrl.searchParams.set('json', 'false');
            window.history.pushState({}, '', newUrl);

            await fetchCollectionData('', true);
        });

        /**
         * Called when user presses back/forward or at initial load:
         * we parse the current URL for ?query= or ?random=,
         * fetch data, summarise, etc.
         */
        async function handlePopState() {
            const urlParams = new URLSearchParams(window.location.search);
            const query = urlParams.get('query') || '';
            const isRandom = urlParams.has('random');

            // Pre-populate the input field
            queryInput.value = query;

            // Only fetch if there's something to do
            if (query || isRandom) {
                await fetchCollectionData(query, isRandom);
            }
        }

        /**
         * Core function to:
         * 1) GET /?json=true with either ?query=... or ?random=true
         * 2) Display results in #resultsList
         * 3) POST /summarise
         * 4) Stream audio from /speak with MediaSource
         */
        async function fetchCollectionData(query, isRandom) {
            try {
                // Step 1: GET from /?json=true ...
                let urlParams = new URLSearchParams();
                urlParams.set('json', 'true');
                if (isRandom) {
                    urlParams.set('random', 'true');
                    urlParams.set('query', 'Show me a random selection of collection items.')
                } else if (query) {
                    urlParams.set('query', query);
                }

                // GET the data
                const response = await fetch('/?' + urlParams.toString(), {
                    method: 'GET',
                });
                const results = await response.json();

                // Display the results
                displayResults(results, isRandom, query, false);

                // Step 2: Summarise
                var summary = await getSummary(urlParams.query, results);
                if (!summary) return;

                // Add the summarised text to our chat transcript <ol>
                const li = document.createElement('li');
                summary = summary.replace(/\\\"/g, '"');
                if (summary.startsWith('"')) {
                    summary = summary.slice(1);
                }
                if (summary.endsWith('"')) {
                    summary = summary.slice(0, -1);
                }
                li.textContent = summary;
                chatsElement.innerHTML = '';
                chatsElement.appendChild(li);
                requestAnimationFrame(() => {
                    // Now toggle the class that triggers the transition
                    li.classList.add('show');
                });

                // Step 3: Stream TTS
                if ('MediaSource' in window && !isFirefox()) {
                    // MSE streaming approach
                    await speakWithStreamTTS(summary.replace('ACMI', 'acmee'));
                } else {
                    // Fallback: fetch entire audio as Blob
                    await speakWithoutStreamTTS(summary.replace('ACMI', 'acmee'));
                }

            } catch (error) {
                console.error('fetchCollectionData error:', error);
            }
        }

        /**
         * Get the connection between a work and the next similar work.
         */
         async function getConnection(work_id) {
            try {
                // GET the data
                const response = await fetch(`/connection?work_id=${work_id}`, {
                    method: 'GET',
                });
                const results = await response.json();
                var connection = results.connection;

                // Display the results
                displayResults(results.works, false, '', true);
                // Add the summarised text to our chat transcript <ol>
                const li = document.createElement('li');
                connection = connection.replace(/\\\"/g, '"');
                if (connection.startsWith('"')) {
                    connection = connection.slice(1);
                }
                if (connection.endsWith('"')) {
                    connection = connection.slice(0, -1);
                }
                li.textContent = connection;
                chatsElement.innerHTML = '';
                chatsElement.appendChild(li);
                requestAnimationFrame(() => {
                    // Now toggle the class that triggers the transition
                    li.classList.add('show');
                });

                // Step 3: Stream TTS
                if ('MediaSource' in window && !isFirefox()) {
                    // MSE streaming approach
                    await speakWithStreamTTS(connection.replace('ACMI', 'acmee'));
                } else {
                    // Fallback: fetch entire audio as Blob
                    await speakWithoutStreamTTS(connection.replace('ACMI', 'acmee'));
                }

            } catch (error) {
                console.error('getConnection error:', error);
            }
        }

        /**
         * Utility: POST to /summarise with the query + results,
         * return the summarised text.
         */
        async function getSummary(query, results) {
            try {
                const response = await fetch('/summarise', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ query, results }),
                });
                // If your /summarise endpoint returns JSON with .content:
                //   const data = await response.json();
                //   return data.content;

                // If it returns plain text (like the default code), do:
                const text = await response.text();
                return text.replace('"\"', '');
            } catch (error) {
                console.error('getSummary error:', error);
                return '';
            }
        }

        /**
         * Utility: Stream TTS audio from /speak using MediaSource, so we can
         * begin playback as soon as some chunks arrive (true streaming).
         */
        async function speakWithStreamTTS(text) {
            try {
                const speakResponse = await fetch('/speak', {
                    method: 'POST',
                    headers: { 'Content-Type': 'text/plain' },
                    body: text,
                });
                if (!speakResponse.ok) {
                    throw new Error('Error from /speak: ' + speakResponse.status);
                }
                if (!speakResponse.body) {
                    throw new Error('ReadableStream not supported or no body returned');
                }

                // Prepare MediaSource for streaming audio
                const mediaSource = new MediaSource();
                audioPlayer.src = URL.createObjectURL(mediaSource);

                // We'll start playback after source is open, so we ensure auto-play
                audioPlayer.play().catch(err => {
                    console.warn('Auto-play might be blocked:', err);
                });

                // When the media source is open, we can feed chunks into a SourceBuffer
                mediaSource.addEventListener('sourceopen', async () => {
                    const sourceBuffer = mediaSource.addSourceBuffer('audio/mpeg');
                    // We'll queue up chunks if the SourceBuffer is busy
                    let isAppending = false;
                    const chunkQueue = [];

                    sourceBuffer.addEventListener('updateend', () => {
                        isAppending = false;
                        if (chunkQueue.length > 0) {
                            appendNextChunk();
                        } else {
                            // No more chunks in queue
                        }
                    });

                    function appendNextChunk() {
                        if (!isAppending && chunkQueue.length > 0 && !sourceBuffer.updating) {
                            isAppending = true;
                            const chunk = chunkQueue.shift();
                            sourceBuffer.appendBuffer(chunk);
                        }
                    }

                    const reader = speakResponse.body.getReader();

                    while (true) {
                        const { value, done } = await reader.read();
                        if (done) {
                            // We've finished receiving audio data from /speak
                            break;
                        }
                        // Enqueue the chunk
                        chunkQueue.push(value.buffer);
                        appendNextChunk();
                    }

                    // Once all chunks are read, we wait for the buffer to finish updating
                    // then end the stream
                    sourceBuffer.addEventListener('updateend', () => {
                        if (sourceBuffer.buffered.length > 0) {
                            // Optional: set mediaSource duration (if needed)
                            // mediaSource.duration = sourceBuffer.buffered.end(0);
                        }
                        // Let the MediaSource know we're done
                        if (mediaSource.readyState === 'open') {
                            mediaSource.endOfStream();
                        }
                    }, { once: true });
                });
            } catch (err) {
                console.error('speakWithStreamTTS error:', err);
            }
        }

        /**
         * Utility: Speak without streaming for devices without MediaSource.
         */
        async function speakWithoutStreamTTS(text) {
            try {
                const speakResponse = await fetch('/speak', {
                    method: 'POST',
                    headers: { 'Content-Type': 'text/plain' },
                    body: text
                });
                if (!speakResponse.ok) {
                    throw new Error('Error from /speak: ' + speakResponse.status);
                }
                // Get entire file as Blob
                const blob = await speakResponse.blob();
                // Set your <audio> element to this Blob
                audioPlayer.src = URL.createObjectURL(blob);
                audioPlayer.play();
            } catch (err) {
                console.error('speakWithoutStreamTTS error:', err);
            }
        }

        /**
         * Display the JSON results from GET /?json=true in <ul id="resultsList">
         */
        function displayResults(results, isRandom, query, isConnection) {
            resultsList.innerHTML = '';
            const heading = document.createElement('h2');
            if (isRandom) {
                heading.innerText = 'A random selection of ACMI works:';
            } else if (isConnection) {
                heading.innerText = 'The connection between these two works:';
            } else {
                heading.innerText = `Algorithmically related works to: ${query}`;
            }
            resultsList.appendChild(heading);
            if (!Array.isArray(results) || results.length === 0) {
                const li = document.createElement('li');
                li.textContent = 'No results found.';
                resultsList.appendChild(li);
                return;
            }
            results.forEach(item => {
                const li = document.createElement('li');
                const title = item.title || 'Untitled';
                const id = item.id || '';
                li.innerHTML = `
                    <a class="circleLink" href="#"><div class="circle"><div class="image"></div></div></a>
                    <h3><a class="titleLink" href="#">${item.title}</a></h3>
                    <p>${item.headline_credit}</p>
                    <p><a href="https://url.acmi.net.au/w/${item.id}" target="_blank" class="read-more">Read more</a></p>
                `;
                resultsList.appendChild(li);
                const circleLink = li.querySelector('.circleLink');
                const titleLink = li.querySelector('.titleLink');
                circleLink.addEventListener('click', (event) => {
                    event.preventDefault();
                    chatsElement.innerHTML = '';
                    resultsList.innerHTML = '';
                    queryInput.value = '';
                    getConnection(item.id);
                });
                titleLink.addEventListener('click', (event) => {
                    event.preventDefault();
                    chatsElement.innerHTML = '';
                    resultsList.innerHTML = '';
                    queryInput.value = '';
                    getConnection(item.id);
                });
                getImage(id).then(imageUrl => {
                if (imageUrl !== '') {
                    const image = li.getElementsByClassName('image')[0];
                    image.style.opacity = '0';
                    setTimeout(() => {
                        image.style.backgroundImage = `url(${imageUrl})`;
                        image.style.backgroundRepeat = 'no-repeat';
                        image.style.backgroundSize = 'cover';
                        image.style.backgroundPosition = 'center';
                        image.title = title;
                        image.alt = title;
                        image.style.opacity = '1';
                    }, 300);
                }
                });
            });
        }

        /**
         * Get an image thumbnail from its XOS Work ID
         */
        async function getImage(work_id) {
            if (!work_id) return '';

            const response = await fetch(`https://embeddings.acmi.net.au/works/${work_id}/`);
            const data = await response.json();
            if (data.thumbnail) {
                return data.thumbnail.image_url;
            }
            return '';
        }

        /**
         * Detect Safari browsers
         */
        function isSafari() {
            const ua = navigator.userAgent;
            const vendor = navigator.vendor;
            return (
                /Safari/.test(ua) &&
                /Apple Computer/.test(vendor) &&
                !/Chrome|CriOS|FxiOS|EdgiOS|Edg|OPR|Opera|Android/.test(ua)
            );
        }

        /**
         * Detect FireFox browsers
         */
        function isFirefox() {
            return navigator.userAgent.toLowerCase().indexOf('firefox') !== -1;
        }
    </script>
</body>

</html>